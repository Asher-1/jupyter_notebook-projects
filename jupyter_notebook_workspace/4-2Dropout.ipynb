{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "\n",
    "def add_layer(inputs, in_size, out_size, n_layer, activation_function = None):\n",
    "    # 添加神经网络层\n",
    "    '''\n",
    "    inputs:              输入数据集\n",
    "    in_size：            当前层的神经元个数\n",
    "    out_size:            下一层神经元个数\n",
    "    n_layer:             第几层\n",
    "    activation_function: 激活函数\n",
    "    '''\n",
    "    layer_name = 'layer%s'% n_layer\n",
    "    with tf.name_scope(layer_name):\n",
    "        with tf.name_scope('weights'):        \n",
    "            Weights = tf.Variable(tf.truncated_normal([in_size, out_size],stddev=0.1), name='W')\n",
    "            tf.summary.histogram(layer_name + \"/weights\", Weights)\n",
    "        with tf.name_scope('biases'):\n",
    "            biases = tf.Variable(tf.zeros([1,out_size]) + 0.1, name='b')\n",
    "            tf.summary.histogram(layer_name + \"/biases\", biases)\n",
    "        with tf.name_scope('Wx_plus_b'):\n",
    "            Wx_plus_b = tf.add(tf.matmul(inputs, Weights), biases)\n",
    "        if activation_function is None:\n",
    "            outputs = Wx_plus_b\n",
    "        else:\n",
    "            outputs = activation_function(Wx_plus_b)\n",
    "            tf.summary.histogram(layer_name + \"/outputs\", outputs)\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#载入数据集\n",
    "mnist = input_data.read_data_sets(\"MNIST_data\",one_hot=True)\n",
    "\n",
    "#每个批次的大小\n",
    "batch_size = 100\n",
    "#计算一共有多少个批次\n",
    "n_batch = mnist.train.num_examples // batch_size\n",
    "\n",
    "#定义两个placeholder\n",
    "with tf.name_scope('inputs'):\n",
    "    x = tf.placeholder(tf.float32,[None,784], name='x_input')\n",
    "    y = tf.placeholder(tf.float32,[None,10], name='y_input')\n",
    "    # keep_prob用于传入当前层神经元保留的百分比\n",
    "    keep_prob=tf.placeholder(tf.float32)\n",
    "\n",
    "#创建一个简单的神经网络\n",
    "# 隐藏层1\n",
    "L1 = add_layer(x, 784, 1000, 1, activation_function = tf.nn.tanh)\n",
    "L1_drop = tf.nn.dropout(L1,keep_prob)\n",
    "# 隐藏层2\n",
    "L2 = add_layer(L1_drop, 1000, 500, 2, activation_function = tf.nn.tanh)\n",
    "L2_drop = tf.nn.dropout(L2,keep_prob) \n",
    "# 输出层(即第三层)\n",
    "prediction = add_layer(L2_drop, 500, 10, 3, activation_function = tf.nn.softmax)\n",
    "\n",
    "\n",
    "# 二次代价函数（适用于输出神经元为线性函数）\n",
    "# loss = tf.reduce_mean(tf.square(y-prediction))\n",
    "\n",
    "with tf.name_scope('loss'):\n",
    "    #交叉熵代价函数(适用于输出神经元为sigmoid函数和softmax函数)\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y,logits=prediction))\n",
    "    tf.summary.scalar('loss', loss)\n",
    "with tf.name_scope('train'):\n",
    "    #使用梯度下降法\n",
    "    train_step = tf.train.GradientDescentOptimizer(0.2).minimize(loss)\n",
    "\n",
    "#初始化变量\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "#结果存放在一个布尔型列表中\n",
    "correct_prediction = tf.equal(tf.argmax(y,1),tf.argmax(prediction,1))#argmax返回一维张量中最大的值所在的位置\n",
    "#求准确率\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    merged = tf.summary.merge_all()\n",
    "    writer = tf.summary.FileWriter(r'./logs/', sess.graph)\n",
    "    # tensorboard --logdir='logs/'\n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoch in range(31):\n",
    "        for batch in range(n_batch):\n",
    "            batch_xs,batch_ys =  mnist.train.next_batch(batch_size)\n",
    "            sess.run(train_step,feed_dict={x:batch_xs,y:batch_ys,keep_prob:0.7})\n",
    "        \n",
    "        result = sess.run(merged, feed_dict={x:mnist.test.images,y:mnist.test.labels,keep_prob:1.0})\n",
    "        writer.add_summary(result, epoch)\n",
    "        test_acc = sess.run(accuracy,feed_dict={x:mnist.test.images,y:mnist.test.labels,keep_prob:1.0})\n",
    "        train_acc = sess.run(accuracy,feed_dict={x:mnist.train.images,y:mnist.train.labels,keep_prob:1.0})\n",
    "        print(\"Iter \" + str(epoch) + \",Testing Accuracy \" + str(test_acc) +\",Training Accuracy \" + str(train_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# keep_prob:1.0(没有使用dropout)-----过拟合\n",
    "Iter 0,Testing Accuracy 0.9338,Training Accuracy 0.933564\n",
    "Iter 1,Testing Accuracy 0.9453,Training Accuracy 0.949928\n",
    "Iter 2,Testing Accuracy 0.9524,Training Accuracy 0.960273\n",
    "Iter 3,Testing Accuracy 0.9582,Training Accuracy 0.966891\n",
    "Iter 4,Testing Accuracy 0.9605,Training Accuracy 0.971546\n",
    "Iter 5,Testing Accuracy 0.9626,Training Accuracy 0.975437\n",
    "Iter 6,Testing Accuracy 0.9632,Training Accuracy 0.977637\n",
    "Iter 7,Testing Accuracy 0.9662,Training Accuracy 0.981037\n",
    "Iter 8,Testing Accuracy 0.9676,Training Accuracy 0.982291\n",
    "...\n",
    "Iter 28,Testing Accuracy 0.975,Training Accuracy 0.992255\n",
    "Iter 29,Testing Accuracy 0.9747,Training Accuracy 0.992382\n",
    "Iter 30,Testing Accuracy 0.9752,Training Accuracy 0.992564\n",
    "\n",
    "# keep_prob:0.7(使用dropout)-------正常拟合\n",
    "Iter 0,Testing Accuracy 0.9206,Training Accuracy 0.914273\n",
    "Iter 1,Testing Accuracy 0.933,Training Accuracy 0.928182\n",
    "Iter 2,Testing Accuracy 0.9383,Training Accuracy 0.934109\n",
    "Iter 3,Testing Accuracy 0.9428,Training Accuracy 0.94\n",
    "Iter 4,Testing Accuracy 0.9457,Training Accuracy 0.946328\n",
    "Iter 5,Testing Accuracy 0.9478,Training Accuracy 0.9492\n",
    "Iter 6,Testing Accuracy 0.9502,Training Accuracy 0.953037\n",
    "Iter 7,Testing Accuracy 0.9518,Training Accuracy 0.954855\n",
    "Iter 8,Testing Accuracy 0.953,Training Accuracy 0.956728\n",
    "...\n",
    "Iter 28,Testing Accuracy 0.9707,Training Accuracy 0.978346\n",
    "Iter 29,Testing Accuracy 0.9707,Training Accuracy 0.978782\n",
    "Iter 30,Testing Accuracy 0.9706,Training Accuracy 0.979418"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
